---
title: "p8105_hw6_yo2336"
author: "Yoo Rim Oh"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(modelr)
```


# Problem 1

## Load and clean data

Load data using `read_csv` and changed columns `babysex`, `frace`, `malform`, and `mrace` 
as factor vectors. 

```{r}
birth_weight =
  read_csv("data/birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate_at(c("babysex", "frace", "malform", "mrace"), as.factor)

summary(is.na(birth_weight))
```

As a result, this data frame has `r ncol(birth_weight)` variables named, 
`r names(birth_weight)` with total of `r nrow(birth_weight)` observations.

In order to check that this data does not have any missing values, used `summary(is.na(birth_weight))`.
No NA present in this data.


## Regression model for birth weight

A linear regression model for birth weight based on hypothesis created using `lm()` and 
named it `birth_weight_fit`. `bwt` was the response and predictors were `bhead`, `blength`, 
`delwt`, `gaweeks`, and `wtgain` to observe how baby's length, head circumference, gestational 
age along with mother's weight gain and weight at the time of delivery effect baby's birth weight.

I hypothesized that the the size of the baby at birth, including length and head circumference, and
the weight of mother in relation to the gestational age would have an effect on the ultimate weight 
of the baby at birth.

```{r}
birth_weight_fit = lm(bwt ~ bhead + blength + delwt + gaweeks + wtgain, data = birth_weight)
broom::tidy(birth_weight_fit) %>%
  knitr::kable()

left_join(add_residuals(birth_weight, birth_weight_fit),
         add_predictions(birth_weight, birth_weight_fit)) %>%
  select(bwt, gaweeks, wtgain, resid, pred) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  labs(title = "Residual vs Fitted", x = "Prediction", y = "Residual")
  
```


## Compare 3 Models

Compared the hypothesis driven model from above (called fit) with a model (called model 1) with 
length at birth and gestational age as predictors and another model (called model 2) with head
circumference, length, sex, and all interactions between. Used `crossv_mc()` to compare in terms of 
the cross-validated prediction error.
```{r}
cv_df = 
  crossv_mc(birth_weight, 100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>%
  mutate(
    fit_model = map(train, ~lm(bwt ~ bhead + blength + delwt + gaweeks + wtgain, data = .x)),
    compare_model_1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    compare_model_2 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + 
                                       bhead * babysex + blength * babysex, data = .x))) %>%
  mutate(
    rmse_fit = map2_dbl(fit_model, test, ~rmse(model = .x, data = .y)),
    rmse_model_1 = map2_dbl(compare_model_1, test, ~rmse(model = .x, data = .y)),
    rmse_model_2 = map2_dbl(compare_model_2, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(title = "3 Model Comparison", x = "Model", y = "RMSE")
```

The model with least amount of predictors (model 1) had generally higher RMSE distribution
when compared with the other 2 models.

# Problem 2

## Load data

Will be focusing on `tmin` and `tmax`.
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


## Bootstrap

Used `bootstrap()` to create 5000 bootstrap samples. These samples were used to evaluate simple 
linear regression with `tmax` as the response and `tmin` as the predictor.
```{r}
weather_bootstrap =
  weather_df %>%
  bootstrap(5000)

bootstrap_results =
  weather_bootstrap %>%
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy),
    results2 = map(models, broom::glance)) %>%
  unnest(results, results2) %>%
  select(.id, term, estimate, r.squared) %>%
  janitor::clean_names()

```

## r^2

The r^2 values were extracted directly from `broom::glance` which were then used to 
calculate 95% confidence interval.
```{r}
bootstrap_results %>%
  ggplot(aes(x = r_squared)) + 
  geom_density() +
  labs(title = "Distribution of r^2")

bootstrap_results %>%
  summarize(
    ci_lower = quantile(r_squared, 0.025), 
    ci_upper = quantile(r_squared, 0.975)) %>%
  knitr::kable(caption = "95% Confidence Interval for r^2")
```

The distribution of r^2 resemble a normal distribution.

## log(β_0∗β_1)

The log(β_0∗β_1) values were calculated from log(`intercept` estimate * `tmin` estimate) which were
then used to calculate 95% confidence interval.
```{r}
log_results =
  bootstrap_results %>%
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) %>%
  janitor::clean_names() %>%
  mutate(log = log(intercept * tmin))

log_results %>%
  ggplot(aes(x = log)) + 
  geom_density() +
  labs(title = "Distribution of log(β_0∗β_1)", x = "log(β_0∗β_1)")

log_results %>%
  summarize(
    ci_lower = quantile(log, 0.025), 
    ci_upper = quantile(log, 0.975)) %>%
  knitr::kable(caption = "95% Confidence Interval for log(β_0∗β_1)")
```

The distribution of log(β_0∗β_1) resemble a normal distribution